{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'I:/Expense tracking/Apple Pay'\n",
    "# folder_path='D:/Personal Projects/Expense tracking/Apple Pay'\n",
    "file_pattern = folder_path + '/*.csv'  # Adjust the pattern if using other formats, e.g., '*.xlsx'\n",
    "\n",
    "# Use glob to find all files matching the pattern\n",
    "file_list = glob.glob(file_pattern)\n",
    "\n",
    "# Read all files and concatenate them into a single DataFrame\n",
    "df_apple_pay = pd.concat((pd.read_csv(file) for file in file_list), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_apple_pay.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_apple_pay['Transaction Date'] = pd.to_datetime(df_apple_pay['Transaction Date'])\n",
    "# df_apple_pay['Transaction Date']=df_apple_pay['Transaction Date'].dt.strftime('%m/%d/%y')\n",
    "# # df_apple_pay['Transaction Date']=pd.to_datetime(df_apple_pay['Transaction Date'], format='%m/%d/%y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_apple_pay=df_apple_pay[['Transaction Date','Description','Category','Amount (USD)','Merchant']]\n",
    "df_apple_pay['Institution']='Apple Pay Credit Card'\n",
    "df_apple_pay['Is Hidden']='No'\n",
    "df_apple_pay['Is Pending']='No'\n",
    "df_apple_pay['Account']='APPLE PAY'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_apple_pay.rename(columns={\"Merchant\":\"Standardized Description\",\"Amount (USD)\":\"Amount\"},inplace=True)\n",
    "dtype_dict = {\n",
    "    'Transaction Date':'datetime64[ns]',\n",
    "    'Description': 'string',\n",
    "    'Institution': 'string',\n",
    "    'Account': 'string',\n",
    "    'Category': 'string',\n",
    "    'Is Hidden': 'string',\n",
    "    'Is Pending': 'string',\n",
    "    'Amount': 'float64',\n",
    "    'Standardized Description': 'string'\n",
    "}\n",
    "df_apple_pay = df_apple_pay.astype(dtype_dict)\n",
    "# df_apple_pay['Transaction Date']=df_apple_pay['Transaction Date'].dt.strftime('%m/%d/%y')\n",
    "df_apple_pay=df_apple_pay[['Transaction Date','Description','Institution','Account','Category','Is Hidden','Is Pending','Amount','Standardized Description']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_apple_pay.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_accounting_to_decimal(amount):\n",
    "    # Remove parentheses and commas\n",
    "    amount = amount.replace('$', '').replace('(', '-').replace(')', '').replace(',', '')\n",
    "    # Convert to float\n",
    "    return float(amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_names = ['Transactions 2022_06-2023_06.csv', 'Transactions 2023_06-2024_06.csv']\n",
    "folder_path = 'I:/Expense tracking'\n",
    "# folder_path='D:/Personal Projects/Expense tracking'\n",
    "file_pattern = folder_path + '/*.csv'  # Adjust the pattern if using other formats, e.g., '*.xlsx'\n",
    "\n",
    "# Use glob to find all files matching the pattern\n",
    "file_list = glob.glob(file_pattern)\n",
    "print(file_list)\n",
    "\n",
    "# Load and concatenate the files into a single DataFrame\n",
    "df = pd.concat([pd.read_csv(file) for file in file_names], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Amount']=df['Amount'].apply(convert_accounting_to_decimal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Standardized Description']=''\n",
    "df.rename(columns={\"Date\":\"Transaction Date\"},inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dtype_dict = {\n",
    "    'Transaction Date':'datetime64[ns]',\n",
    "    'Description': 'string',\n",
    "    'Institution': 'string',\n",
    "    'Account': 'string',\n",
    "    'Category': 'string',\n",
    "    'Is Hidden': 'string',\n",
    "    'Is Pending': 'string',\n",
    "    'Amount': 'float64',\n",
    "    'Standardized Description': 'string'\n",
    "}\n",
    "df = df.astype(dtype_dict)\n",
    "# len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Account'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full=pd.concat([df,df_apple_pay],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.reset_option('display.max_rows')\n",
    "# pd.reset_option('display.max_columns')\n",
    "df_full[df_full['Account']=='APPLE PAY']['Category'].unique()\n",
    "df_full[df_full['Category']=='Medical']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full['Category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns_map = {\n",
    "    'COFFEE': [r'STARBUCKS', r'DUNKIN',r'PANERA'],\n",
    "    'SHOPPING':[r'WALMART',r'TARGET'],\n",
    "    'RENT':[r'BELL WEB',r'SUMMIT',r'PALMS ASSOCIATES'],\n",
    "    'ENERGY, GAS & ELECTRIC':[r'TXU'],\n",
    "    'RESTAURANTS/DINING':[r'HELLO INDIA',r'HELLO! INDIA'],\n",
    "    'SUBSCRIPTIONS':[r'ENVATO',r'STRATA',r'VIDIQ',r'YOUTUBE',r'HUNTER.IO'],\n",
    "    'PAYMENT':[r'USCIS',r'ZELLE PAYMENT TO'],\n",
    "    'INCOME':[r'ZELLE PAYMENT FROM'],\n",
    "    'ENTERTAINMENT':[r'SIXFLAGS'],\n",
    "    'GYM':[r'CRUNCH']\n",
    "}\n",
    "\n",
    "# Function to map the new category\n",
    "def map_category(row):\n",
    "    description_upper = row['Description'].upper()  # Convert to uppercase for case-insensitive matching\n",
    "    for category, patterns in patterns_map.items():\n",
    "        if any(re.search(pattern, description_upper) for pattern in patterns):\n",
    "            return category\n",
    "    return row['Category'].upper()\n",
    "    \n",
    "df_full['Category'] = df_full.apply(map_category, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_category_dict={\n",
    "'SHOPPING/GROCERIES':['Groceries','Grocery','Shopping','Furniture & Home Decor','Merchandise/Misc','Gifts','Clothing','Home Improvement/Maintenance','Books','Electronics & Software'],\n",
    "'ENTERTAINMENT':['Entertainment','Air Travel','Hotel','Rental Car','Travel & Vacation'],\n",
    "'FOOD AND DINING':['Restaurants','Restaurants/Dining','Fast Food & Convenience',\t'Coffee','Food','Alcohol & Bars'],\n",
    "'SUBSCRIPTIONS':['Subscriptions','Education'],\n",
    "'HEALTH':['Gym'],\n",
    "'BILLS AND UTILITIES':['Phone, Internet & Cable','Gas & Fuel','Gas','Insurance','Auto Service','Energy, Gas & Electric','Auto & Transport',\n",
    "                       \t'Water'\t,'Bills & Utilities','Rent','Tolls','Rideshare','Parking','Pharmacy','Hair & Nails','Medical','Household Services'],\n",
    "'MISCELLANEOUS':['Transfers','Credit Card Payment','Savings','Investment Savings','Investment Transfers','Online Payment','Bank Fee'\n",
    "                 \t,'Fees & Charges','Shipping & Handling','Taxes','Cash/ATM','Charity','Payment','Other'],\n",
    "'INCOME':['Interest Income','Paycheck/Salary','Tax Refund','Income']\n",
    "    \n",
    "}\n",
    "\n",
    "def map_category(row):\n",
    "    for category, patterns in master_category_dict.items():\n",
    "        if any(pattern.lower() in row['Category'].lower() for pattern in patterns):\n",
    "            return category\n",
    "    return 'OTHER'\n",
    "    \n",
    "df_full['Master Category'] = df_full.apply(map_category, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full['Master Category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_map = {\n",
    "    'STARBUCKS': [r'STARBUCKS'],\n",
    "    'DUNKIN': [r'DUNKIN'],\n",
    "    '7-ELEVEN':[r'7-ELEVEN'],\n",
    "    'WALMART':[r'WALMART',r'WM',r'WAL-MART'],\n",
    "    'TARGET':[r'TARGET'],\n",
    "    'HOME DEPOT':[r'HOME DEPOT'],\n",
    "    'AMAZON':[r'AMAZON',r'AMZN'],\n",
    "    'COSTCO':[r'COSTCO'],\n",
    "    'HELLO INDIA': [r'HELLO INDIA',r'HELLO! INDIA']\n",
    "}\n",
    "\n",
    "def map_description(row):\n",
    "    description_upper = row['Description'].upper()  # Convert to uppercase for case-insensitive matching\n",
    "    for category, patterns in desc_map.items():\n",
    "        if any(re.search(pattern, description_upper) for pattern in patterns):\n",
    "            return category\n",
    "    return row['Description'].upper()\n",
    "    \n",
    "\n",
    "# Apply the function to create a new column 'Mapped Description'\n",
    "df_full['Standardized Description'] = df_full.apply(map_description,axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter out 7 ELEVEN as it needs cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filtered_df = df_full[~(df_full['Description'].str.match('7-ELEVEN', case=False, na=False) & (df_full['Category'] == 'FAST FOOD & CONVENIENCE'))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7-ELEVEN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_7_eleven = df_full[df_full['Description'].str.match('7-ELEVEN', case=False, na=False) & (df_full['Category']=='FAST FOOD & CONVENIENCE')]\n",
    "df_7_eleven.loc[:,'Amount']=df_7_eleven['Amount']+2.0\n",
    "df_7_eleven_coffee=df_7_eleven.copy()\n",
    "df_7_eleven_coffee.loc[:,'Amount']=-2.00\n",
    "df_7_eleven_coffee.loc[:,'Category']='COFFEE'\n",
    "df_7_eleven_coffee.loc[:,'Master Category']='FOOD AND DINING'\n",
    "\n",
    "df_7_eleven_transformed = pd.concat([df_7_eleven_coffee, df_7_eleven], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final=pd.concat([filtered_df, df_7_eleven_transformed], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_final)\n",
    "df_final.head(100)\n",
    "len(df_final[(df_final['Transaction Date'] >= '2022-06-01') & (df_final['Transaction Date'] <= '2024-07-01')])\n",
    "sum(df_final.isnull().any(axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_df.groupby('Standardized Description')['Amount'].sum().sort_values(ascending=True)\n",
    "# filtered_df['Amount'].sum()\n",
    "df_final.to_csv('Transactions Full.csv')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
